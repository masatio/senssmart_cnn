{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd95b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedGroupKFold\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score, accuracy_score, classification_report\n",
    "\n",
    "import fusion_model\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c84fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Čitanje podataka; formiranje baze koja se sastoji od rečnika sa EKG, PPG, PCG i ACC signalima\n",
    "###############################################################################################\n",
    "\n",
    "ppg_data = pd.read_csv('ppg_beats_for_classification_fixed_length_20_hz.csv')\n",
    "ppg_data = ppg_data[~np.isnan(ppg_data.iloc[:,-1])]\n",
    "\n",
    "y = ppg_data.iloc[:,-1].to_numpy() # označene labele\n",
    "y_bin = (y != 0).astype(int) # binarne labele\n",
    "subjects = ppg_data.iloc[:,-2] # ovde imam sve ispitanike \n",
    "\n",
    "ppg_data = ppg_data.iloc[:,:-2].to_numpy()\n",
    "\n",
    "ecg_data = pd.read_csv('ecg_beats_for_classification_fixed_length_500_hz.csv')\n",
    "ecg_data= ecg_data[~np.isnan(ecg_data.iloc[:,-1])].iloc[:,:-2].to_numpy()\n",
    "\n",
    "pcg_data = pd.read_csv('pcg_beats_for_classification_fixed_length_200_hz.csv')\n",
    "pcg_data= pcg_data[~np.isnan(pcg_data.iloc[:,-1])].iloc[:,:-2].to_numpy()\n",
    "\n",
    "acc_data = pd.read_csv('acc_beats_for_classification_fixed_length_50_hz.csv')\n",
    "acc_data= acc_data[~np.isnan(acc_data.iloc[:,-1])].iloc[:,:-2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05dfc2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_data = torch.tensor(ppg_data, dtype=torch.float32)\n",
    "pcg_data = torch.tensor(pcg_data, dtype=torch.float32)\n",
    "ecg_data = torch.tensor(ecg_data, dtype=torch.float32)\n",
    "acc_data = torch.tensor(acc_data, dtype=torch.float32)\n",
    "y = torch.tensor(y_bin, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f1790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mešanje podataka iz skupa (obučavajućeg)\n",
    "def shuffle_data(ppg_data, pcg_data, acc_data, y):\n",
    "    indices = np.arange(len(y))\n",
    "    np.random.shuffle(indices)\n",
    "    indices = torch.tensor(indices)\n",
    "    return [ppg_data[indices], pcg_data[indices], acc_data[indices]], y[indices]\n",
    "\n",
    "def train_val_split(X_train_val, y_train_val, groups_train_val, outer_fold):\n",
    "    inner_kf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=outer_fold + 42)\n",
    "\n",
    "    for inner_train_idx, inner_val_idx in inner_kf.split(X_train_val, y_train_val, groups_train_val):\n",
    "        return inner_train_idx, inner_val_idx\n",
    "    \n",
    "def scaler_fitting(X_train):\n",
    "    scaler_ppg = StandardScaler()\n",
    "    scaler_pcg = StandardScaler()\n",
    "    scaler_acc = StandardScaler()\n",
    "    X_train_ppg = scaler_ppg.fit_transform(X_train[0]).astype(np.float32)\n",
    "    X_train_pcg = scaler_pcg.fit_transform(X_train[1]).astype(np.float32)\n",
    "    X_train_acc = scaler_acc.fit_transform(X_train[2]).astype(np.float32)\n",
    "\n",
    "    X_train = [X_train_ppg, X_train_pcg, X_train_acc]\n",
    "\n",
    "    return X_train, scaler_ppg, scaler_pcg, scaler_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14538ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_estimation(model, criterion, X, y, groups):\n",
    "    \n",
    "    outputs = fusion_model.model_output(model, criterion, X, y)\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    sigmoids = defaultdict(list)\n",
    "    predictions = defaultdict(float)\n",
    "    true_labels = defaultdict(float)\n",
    "    counter_true = 0\n",
    "    counter = 0\n",
    "    for i in range(0, np.shape(groups)[0]):\n",
    "        sigmoids[groups.iloc[i]].append(np.round(outputs[i]))\n",
    "        true_labels[groups.iloc[i]] = y[i]\n",
    "    for subj in sigmoids:\n",
    "        counter = counter + 1\n",
    "        #predictions[subj] = np.round(np.mean(sigmoids[subj]))\n",
    "        classes, counts = torch.unique(torch.tensor(sigmoids[subj]), return_counts=True)\n",
    "        predictions[subj] = classes[torch.argmax(counts)]\n",
    "        if predictions[subj] == true_labels[subj]:\n",
    "            counter_true = counter_true + 1\n",
    "    \n",
    "    return counter_true/counter\n",
    "\n",
    "def accuracy_estimation_multiclass(model, criterion, X, y, groups):\n",
    "\n",
    "    outputs = fusion_model.model_output(model, criterion, X, y)\n",
    "    outputs = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "    softmaxes = defaultdict(list)\n",
    "    predictions = defaultdict(float)\n",
    "    true_labels = defaultdict(float)\n",
    "    counter_true = 0\n",
    "    counter = 0\n",
    "    for i in range(0, np.shape(groups)[0]):\n",
    "        softmaxes[groups.iloc[i]].append(outputs[i])\n",
    "        true_labels[groups.iloc[i]] = y[i]\n",
    "    for subj in softmaxes:\n",
    "        counter = counter + 1\n",
    "        classes, counts = torch.unique(torch.tensor(softmaxes[subj]), return_counts=True)\n",
    "        predictions[subj] = classes[torch.argmax(counts)]\n",
    "        if predictions[subj] == true_labels[subj]:\n",
    "            counter_true = counter_true + 1\n",
    "    return counter_true/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce0af86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Outer Fold 1 ===\n",
      "Epoch 1: Train Loss=0.4490, Train Acc=0.7868, Val Loss=0.9558, Val Acc=0.6169\n",
      "Epoch 2: Train Loss=0.3458, Train Acc=0.8433, Val Loss=1.0770, Val Acc=0.5842\n",
      "Epoch 3: Train Loss=0.3097, Train Acc=0.8647, Val Loss=1.4062, Val Acc=0.5329\n",
      "Epoch 4: Train Loss=0.2780, Train Acc=0.8841, Val Loss=1.0547, Val Acc=0.6304\n",
      "Early stopping triggered. Restoring best weights.\n",
      "Test Accuracy: 0.8645\n",
      "\n",
      "=== Outer Fold 2 ===\n",
      "Epoch 1: Train Loss=0.5110, Train Acc=0.7534, Val Loss=0.5582, Val Acc=0.6943\n",
      "Epoch 2: Train Loss=0.4168, Train Acc=0.8144, Val Loss=0.5562, Val Acc=0.6967\n",
      "Epoch 3: Train Loss=0.3604, Train Acc=0.8539, Val Loss=0.5767, Val Acc=0.7343\n",
      "Epoch 4: Train Loss=0.3258, Train Acc=0.8674, Val Loss=0.6511, Val Acc=0.7117\n",
      "Epoch 5: Train Loss=0.3062, Train Acc=0.8800, Val Loss=0.5755, Val Acc=0.7381\n",
      "Early stopping triggered. Restoring best weights.\n",
      "Test Accuracy: 0.8374\n",
      "\n",
      "=== Outer Fold 3 ===\n",
      "Epoch 1: Train Loss=0.4933, Train Acc=0.7609, Val Loss=0.6368, Val Acc=0.6687\n",
      "Epoch 2: Train Loss=0.3979, Train Acc=0.8275, Val Loss=0.6481, Val Acc=0.6792\n",
      "Epoch 3: Train Loss=0.3674, Train Acc=0.8404, Val Loss=0.6313, Val Acc=0.7078\n",
      "Epoch 4: Train Loss=0.3459, Train Acc=0.8542, Val Loss=0.6118, Val Acc=0.7097\n",
      "Epoch 5: Train Loss=0.3210, Train Acc=0.8676, Val Loss=0.6147, Val Acc=0.7345\n",
      "Epoch 6: Train Loss=0.3106, Train Acc=0.8723, Val Loss=0.5842, Val Acc=0.7421\n",
      "Epoch 7: Train Loss=0.2964, Train Acc=0.8792, Val Loss=0.5736, Val Acc=0.7431\n",
      "Epoch 8: Train Loss=0.2812, Train Acc=0.8865, Val Loss=0.5699, Val Acc=0.7617\n",
      "Epoch 9: Train Loss=0.2717, Train Acc=0.8941, Val Loss=0.5504, Val Acc=0.7755\n",
      "Epoch 10: Train Loss=0.2622, Train Acc=0.8952, Val Loss=0.5473, Val Acc=0.7698\n",
      "Epoch 11: Train Loss=0.2533, Train Acc=0.8982, Val Loss=0.5081, Val Acc=0.7893\n",
      "Epoch 12: Train Loss=0.2420, Train Acc=0.9046, Val Loss=0.5116, Val Acc=0.7831\n",
      "Epoch 13: Train Loss=0.2368, Train Acc=0.9079, Val Loss=0.4945, Val Acc=0.7984\n",
      "Epoch 14: Train Loss=0.2271, Train Acc=0.9110, Val Loss=0.5351, Val Acc=0.7831\n",
      "Epoch 15: Train Loss=0.2247, Train Acc=0.9121, Val Loss=0.5426, Val Acc=0.7841\n",
      "Epoch 16: Train Loss=0.2155, Train Acc=0.9151, Val Loss=0.5169, Val Acc=0.7660\n",
      "Early stopping triggered. Restoring best weights.\n",
      "Test Accuracy: 0.7392\n",
      "\n",
      "=== Outer Fold 4 ===\n",
      "Epoch 1: Train Loss=0.5213, Train Acc=0.7394, Val Loss=0.7010, Val Acc=0.6436\n",
      "Epoch 2: Train Loss=0.4141, Train Acc=0.8156, Val Loss=0.6607, Val Acc=0.6519\n",
      "Epoch 3: Train Loss=0.3450, Train Acc=0.8598, Val Loss=0.7070, Val Acc=0.6725\n",
      "Epoch 4: Train Loss=0.3074, Train Acc=0.8824, Val Loss=0.7998, Val Acc=0.6509\n",
      "Epoch 5: Train Loss=0.2830, Train Acc=0.8867, Val Loss=0.7408, Val Acc=0.6756\n",
      "Early stopping triggered. Restoring best weights.\n",
      "Test Accuracy: 0.7045\n",
      "\n",
      "=== Outer Fold 5 ===\n",
      "Epoch 1: Train Loss=0.5199, Train Acc=0.7254, Val Loss=0.8342, Val Acc=0.5777\n",
      "Epoch 2: Train Loss=0.4266, Train Acc=0.7966, Val Loss=0.8092, Val Acc=0.6859\n",
      "Epoch 3: Train Loss=0.3654, Train Acc=0.8391, Val Loss=0.8664, Val Acc=0.6923\n",
      "Epoch 4: Train Loss=0.3252, Train Acc=0.8632, Val Loss=0.6400, Val Acc=0.7506\n",
      "Epoch 5: Train Loss=0.2948, Train Acc=0.8802, Val Loss=0.8138, Val Acc=0.7163\n",
      "Epoch 6: Train Loss=0.2716, Train Acc=0.8939, Val Loss=0.8865, Val Acc=0.7144\n",
      "Epoch 7: Train Loss=0.2579, Train Acc=0.8988, Val Loss=0.8196, Val Acc=0.7232\n",
      "Early stopping triggered. Restoring best weights.\n",
      "Test Accuracy: 0.8401\n",
      "Mean test accuracy: 0.7971, std: 0.0631\n",
      "Mean test precision: 0.7558, std: 0.0781\n",
      "Mean test recall: 0.9356, std: 0.0634\n",
      "Mean test F1 score: 0.8333, std: 0.0551\n",
      "Mean test voted accuracy: 0.8183, std: 0.1213\n"
     ]
    }
   ],
   "source": [
    "ecg_shape = (417, 1)\n",
    "ppg_shape = (17, 1)\n",
    "pcg_shape = (167,1)\n",
    "acc_shape = (42, 1)\n",
    "num_classes = 4\n",
    "class_names = [\"class0\", \"class1\"] #\"class2\", \"class3\"]\n",
    "\n",
    "precisions = []\n",
    "f1scores = []\n",
    "recalls = []\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "groups = subjects\n",
    "\n",
    "outer_kf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "estimated_accuracies = []\n",
    "all_reports = {cls: {'precision': [], 'recall': [], 'f1-score': []} for cls in class_names}\n",
    "\n",
    "for outer_fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(ppg_data, y, groups)):\n",
    "    print(f\"\\n=== Outer Fold {outer_fold+1} ===\")\n",
    "    model = fusion_model.MultiRateCNN()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, min_lr=1e-4)\n",
    "\n",
    "    #X_train_val = [ppg_data[train_val_idx], pcg_data[train_val_idx], acc_data[train_val_idx]]\n",
    "    X_test = [ppg_data[test_idx], pcg_data[test_idx], acc_data[test_idx]]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    \n",
    "    groups_train_val = groups.iloc[train_val_idx]\n",
    "    groups_test = groups.iloc[test_idx]\n",
    "    train_idx, val_idx = train_val_split(train_val_idx, y_train_val, groups_train_val, outer_fold)\n",
    "\n",
    "    X_train, y_train = [ppg_data[train_idx], pcg_data[train_idx], acc_data[train_idx]], y[train_idx]\n",
    "    X_val, y_val = [ppg_data[val_idx], pcg_data[val_idx], acc_data[val_idx]], y[val_idx]\n",
    "\n",
    "    # TODO: Standardization - must be added here\n",
    "    X_train, scaler_ppg, scaler_pcg, scaler_acc = scaler_fitting(X_train)\n",
    "    X_val = [scaler_ppg.transform(X_val[0]).astype(np.float32), scaler_pcg.transform(X_val[1]).astype(np.float32), scaler_acc.transform(X_val[2]).astype(np.float32)]\n",
    "    X_test = [scaler_ppg.transform(X_test[0]).astype(np.float32), scaler_pcg.transform(X_test[1]).astype(np.float32), scaler_acc.transform(X_test[2]).astype(np.float32)]\n",
    "\n",
    "    #X_train, y_train = shuffle_data(X_train[0], X_train[1], X_train[2], y_train)\n",
    "    #X_val, y_val = shuffle_data(X_val[0], X_val[1], X_val[2], y_val)\n",
    "    \n",
    "    model = fusion_model.train_model(model, criterion, optimizer, scheduler, X_train, y_train, X_val, y_val, batch_size=32, epochs=50)\n",
    "    \n",
    "    acc = fusion_model.evaluate_model(model, criterion, X_test, y_test)\n",
    "    outputs = fusion_model.model_output(model, criterion, X_test, y_test)\n",
    "    #y_pred = torch.argmax(outputs, dim=1)\n",
    "    y_pred = (torch.sigmoid(outputs) > 0.5)\n",
    "    report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
    "    for cls in class_names:\n",
    "        for metric in ['precision', 'recall', 'f1-score']:\n",
    "            all_reports[cls][metric].append(report[cls][metric])\n",
    "\n",
    "    acc_vote = accuracy_estimation(model, criterion, X_test, y_test, groups_test)\n",
    "\n",
    "    precisions.append(precision_score(y_test, y_pred))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1scores.append(f1_score(y_test, y_pred))\n",
    "    accuracies.append(acc)\n",
    "    estimated_accuracies.append(acc_vote)\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(f\"Mean test accuracy: {np.mean(accuracies):.4f}, std: {np.std(accuracies):.4f}\")\n",
    "print(f\"Mean test precision: {np.mean(precisions):.4f}, std: {np.std(precisions):.4f}\")\n",
    "print(f\"Mean test recall: {np.mean(recalls):.4f}, std: {np.std(recalls):.4f}\")\n",
    "print(f\"Mean test F1 score: {np.mean(f1scores):.4f}, std: {np.std(f1scores):.4f}\")\n",
    "print(f\"Mean test voted accuracy: {np.mean(estimated_accuracies):.4f}, std: {np.std(estimated_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c7c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Precision (mean ± std) Recall (mean ± std) F1 (mean ± std)\n",
      "class0            0.77 ± 0.09         0.71 ± 0.16     0.72 ± 0.09\n",
      "class1            0.48 ± 0.21         0.59 ± 0.11     0.51 ± 0.17\n",
      "class2            0.32 ± 0.31         0.16 ± 0.16     0.21 ± 0.21\n",
      "class3            0.61 ± 0.13         0.69 ± 0.19     0.64 ± 0.13\n"
     ]
    }
   ],
   "source": [
    "summary = pd.DataFrame(index=class_names, columns=['Precision (mean ± std)', 'Recall (mean ± std)', 'F1 (mean ± std)'])\n",
    "\n",
    "for cls in class_names:\n",
    "    precision = np.array(all_reports[cls]['precision'])\n",
    "    recall = np.array(all_reports[cls]['recall'])\n",
    "    f1 = np.array(all_reports[cls]['f1-score'])\n",
    "\n",
    "    summary.loc[cls, 'Precision (mean ± std)'] = f\"{precision.mean():.2f} ± {precision.std():.2f}\"\n",
    "    summary.loc[cls, 'Recall (mean ± std)'] = f\"{recall.mean():.2f} ± {recall.std():.2f}\"\n",
    "    summary.loc[cls, 'F1 (mean ± std)'] = f\"{f1.mean():.2f} ± {f1.std():.2f}\"\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a761067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MultiRateCNN                             [1, 4]                    --\n",
       "├─Sequential: 1-1                        [1, 16, 17]               --\n",
       "│    └─Conv1d: 2-1                       [1, 8, 84]                48\n",
       "│    └─BatchNorm1d: 2-2                  [1, 8, 84]                16\n",
       "│    └─ReLU: 2-3                         [1, 8, 84]                --\n",
       "│    └─MaxPool1d: 2-4                    [1, 8, 42]                --\n",
       "│    └─Conv1d: 2-5                       [1, 16, 21]               400\n",
       "│    └─BatchNorm1d: 2-6                  [1, 16, 21]               32\n",
       "│    └─ReLU: 2-7                         [1, 16, 21]               --\n",
       "│    └─AdaptiveAvgPool1d: 2-8            [1, 16, 17]               --\n",
       "├─Sequential: 1-2                        [1, 16, 17]               --\n",
       "│    └─Conv1d: 2-9                       [1, 8, 42]                48\n",
       "│    └─BatchNorm1d: 2-10                 [1, 8, 42]                16\n",
       "│    └─ReLU: 2-11                        [1, 8, 42]                --\n",
       "│    └─MaxPool1d: 2-12                   [1, 8, 21]                --\n",
       "│    └─Conv1d: 2-13                      [1, 16, 21]               400\n",
       "│    └─BatchNorm1d: 2-14                 [1, 16, 21]               32\n",
       "│    └─ReLU: 2-15                        [1, 16, 21]               --\n",
       "│    └─AdaptiveAvgPool1d: 2-16           [1, 16, 17]               --\n",
       "├─Sequential: 1-3                        [1, 16, 17]               --\n",
       "│    └─Conv1d: 2-17                      [1, 8, 17]                32\n",
       "│    └─BatchNorm1d: 2-18                 [1, 8, 17]                16\n",
       "│    └─ReLU: 2-19                        [1, 8, 17]                --\n",
       "│    └─Conv1d: 2-20                      [1, 16, 17]               400\n",
       "│    └─BatchNorm1d: 2-21                 [1, 16, 17]               32\n",
       "│    └─ReLU: 2-22                        [1, 16, 17]               --\n",
       "│    └─AdaptiveAvgPool1d: 2-23           [1, 16, 17]               --\n",
       "├─Sequential: 1-4                        [1, 4]                    --\n",
       "│    └─Conv1d: 2-24                      [1, 16, 15]               2,320\n",
       "│    └─ReLU: 2-25                        [1, 16, 15]               --\n",
       "│    └─Dropout: 2-26                     [1, 16, 15]               --\n",
       "│    └─AdaptiveAvgPool1d: 2-27           [1, 16, 1]                --\n",
       "│    └─Flatten: 2-28                     [1, 16]                   --\n",
       "│    └─Linear: 2-29                      [1, 4]                    68\n",
       "==========================================================================================\n",
       "Total params: 3,860\n",
       "Trainable params: 3,860\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.07\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.04\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Example input shapes\n",
    "ppg_input = torch.randn(1, 17).float()     # [batch_size, features]\n",
    "pcg_input = torch.randn(1, 167).float()\n",
    "acc_input = torch.randn(1, 42).float()\n",
    "\n",
    "# Create model instance\n",
    "model = fusion_model.MultiRateCNN()\n",
    "\n",
    "# Print summary\n",
    "summary(model, input_data=(ppg_input, pcg_input, acc_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
